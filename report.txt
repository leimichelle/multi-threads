We extended our lab 3 implementation in this lab. In lab 3, we implemented segregated linked list for the global heap. In this lab, we divided up our global heap into multiple heaps, each managed by its own arena. Each arena has its own segregated linked list and an ID that matches a processor. Our implementation originally lets threads wait for any available arena, but we later found that performance improved when each processor was given its own arena. Each processor is able to operate concurrently. We still required a lock due to cross-processor mallocs and frees. In our implementation, individual heaps need not be continuous memory regions either and we coalesce neighbor free blocks; thus, our implementation has low external fragmentation. Our TA also confirmed that we are allowed to add overhead to the single-threaded malloc (since our sequential implementation is very fast), in order to improve parallel performance.
